{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[517 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/navee/OneDrive/Desktop/Data Science Assignments/Assignment 16 - Neural Networks/forestfires.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#Checking for null values & data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Since number of columns are more, let's use PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling the data (leaving out the target variable, and the taking only the numerical data for input)\n",
    "df1= df.iloc[:,2:30]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(df1)\n",
    "df_norm = sc.transform(df1)\n",
    "df_norm                     #Normalised dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  4.98037274e-16, -2.73530281e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02, -9.55928328e-15,  1.15055466e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  2.58690766e-15, -5.66797432e-17],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -1.84247930e-16,  2.36645381e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -2.30354869e-16,  2.72058887e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  5.70142521e-17,  8.50237385e-17]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 28)\n",
    "pca_values = pca.fit_transform(df_norm)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 1.95971390e-33])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The amount of variance that each PCA explains is \n",
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cumulative variance \n",
    "var1 = np.cumsum(np.round(var,decimals = 4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Variance plot for PCA components obtained\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(var1,color=\"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Selecting first 24 PCAs out of total 28**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf = pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                     df[['size_category']]], axis = 1)\n",
    "finalDf.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into input (X) and output (Y) variables\n",
    "array = finalDf.values\n",
    "X = array[:,0:24]\n",
    "Y = array[:,24]\n",
    "\n",
    "X.reshape(-1,1)\n",
    "Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 1s 25ms/step - loss: 0.6880 - accuracy: 0.5769 - val_loss: 0.6582 - val_accuracy: 0.6218\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6118 - accuracy: 0.6736 - val_loss: 0.6705 - val_accuracy: 0.6346\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7309 - val_loss: 0.6852 - val_accuracy: 0.6603\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7578 - val_loss: 0.6942 - val_accuracy: 0.6859\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.7822 - val_loss: 0.7042 - val_accuracy: 0.6859\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8082 - val_loss: 0.7116 - val_accuracy: 0.6859\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5219 - accuracy: 0.7523 - val_loss: 0.7079 - val_accuracy: 0.6795\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.7656 - val_loss: 0.7114 - val_accuracy: 0.6859\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.8175 - val_loss: 0.7094 - val_accuracy: 0.6859\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4438 - accuracy: 0.8106 - val_loss: 0.7009 - val_accuracy: 0.6923\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7716 - val_loss: 0.6986 - val_accuracy: 0.6987\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7946 - val_loss: 0.7023 - val_accuracy: 0.6987\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7943 - val_loss: 0.6929 - val_accuracy: 0.6987\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8365 - val_loss: 0.7043 - val_accuracy: 0.6987\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4417 - accuracy: 0.7884 - val_loss: 0.7049 - val_accuracy: 0.6923\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.8091 - val_loss: 0.7032 - val_accuracy: 0.6987\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4015 - accuracy: 0.8205 - val_loss: 0.7001 - val_accuracy: 0.7051\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3997 - accuracy: 0.8106 - val_loss: 0.6999 - val_accuracy: 0.7115\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4004 - accuracy: 0.8160 - val_loss: 0.6921 - val_accuracy: 0.7115\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3893 - accuracy: 0.8354 - val_loss: 0.6950 - val_accuracy: 0.7115\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8077 - val_loss: 0.6958 - val_accuracy: 0.7244\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8367 - val_loss: 0.6948 - val_accuracy: 0.7308\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8553 - val_loss: 0.6953 - val_accuracy: 0.7244\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8454 - val_loss: 0.6987 - val_accuracy: 0.7308\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8449 - val_loss: 0.6946 - val_accuracy: 0.7308\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3915 - accuracy: 0.8098 - val_loss: 0.7040 - val_accuracy: 0.7308\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3430 - accuracy: 0.8323 - val_loss: 0.7134 - val_accuracy: 0.7308\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8601 - val_loss: 0.7196 - val_accuracy: 0.7372\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3122 - accuracy: 0.8667 - val_loss: 0.7058 - val_accuracy: 0.7500\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8832 - val_loss: 0.7116 - val_accuracy: 0.7500\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8720 - val_loss: 0.7129 - val_accuracy: 0.7500\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2497 - accuracy: 0.9129 - val_loss: 0.7212 - val_accuracy: 0.7436\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2608 - accuracy: 0.9115 - val_loss: 0.7168 - val_accuracy: 0.7500\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.8800 - val_loss: 0.7128 - val_accuracy: 0.7500\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2389 - accuracy: 0.9222 - val_loss: 0.7248 - val_accuracy: 0.7564\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2504 - accuracy: 0.9165 - val_loss: 0.7254 - val_accuracy: 0.7564\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2677 - accuracy: 0.9149 - val_loss: 0.7334 - val_accuracy: 0.7628\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2660 - accuracy: 0.8821 - val_loss: 0.7365 - val_accuracy: 0.7628\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9202 - val_loss: 0.7338 - val_accuracy: 0.7564\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2696 - accuracy: 0.9048 - val_loss: 0.7314 - val_accuracy: 0.7692\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2186 - accuracy: 0.9186 - val_loss: 0.7416 - val_accuracy: 0.7628\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9154 - val_loss: 0.7417 - val_accuracy: 0.7692\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.9223 - val_loss: 0.7443 - val_accuracy: 0.7885\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.9306 - val_loss: 0.7439 - val_accuracy: 0.7756\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2119 - accuracy: 0.9119 - val_loss: 0.7487 - val_accuracy: 0.7885\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.9128 - val_loss: 0.7479 - val_accuracy: 0.7885\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2092 - accuracy: 0.9248 - val_loss: 0.7492 - val_accuracy: 0.7949\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.9160 - val_loss: 0.7576 - val_accuracy: 0.7885\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1923 - accuracy: 0.9271 - val_loss: 0.7584 - val_accuracy: 0.7885\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9153 - val_loss: 0.7620 - val_accuracy: 0.7885\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1890 - accuracy: 0.9269 - val_loss: 0.7704 - val_accuracy: 0.7885\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.9374 - val_loss: 0.7734 - val_accuracy: 0.7756\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1596 - accuracy: 0.9426 - val_loss: 0.7761 - val_accuracy: 0.7756\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1657 - accuracy: 0.9416 - val_loss: 0.7850 - val_accuracy: 0.7692\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.9383 - val_loss: 0.7841 - val_accuracy: 0.7821\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.9424 - val_loss: 0.8034 - val_accuracy: 0.7500\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9314 - val_loss: 0.7976 - val_accuracy: 0.7756\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9284 - val_loss: 0.8047 - val_accuracy: 0.7628\n",
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1554 - accuracy: 0.9390 - val_loss: 0.8080 - val_accuracy: 0.7628\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1303 - accuracy: 0.9652 - val_loss: 0.8223 - val_accuracy: 0.7628\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1320 - accuracy: 0.9631 - val_loss: 0.8174 - val_accuracy: 0.7821\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1375 - accuracy: 0.9493 - val_loss: 0.8339 - val_accuracy: 0.7692\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1383 - accuracy: 0.9538 - val_loss: 0.8423 - val_accuracy: 0.7756\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9515 - val_loss: 0.8348 - val_accuracy: 0.7885\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1195 - accuracy: 0.9625 - val_loss: 0.8496 - val_accuracy: 0.7885\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1253 - accuracy: 0.9633 - val_loss: 0.8498 - val_accuracy: 0.7949\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1395 - accuracy: 0.9498 - val_loss: 0.8644 - val_accuracy: 0.7949\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1165 - accuracy: 0.9610 - val_loss: 0.8606 - val_accuracy: 0.7949\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9472 - val_loss: 0.8694 - val_accuracy: 0.7821\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0998 - accuracy: 0.9670 - val_loss: 0.8750 - val_accuracy: 0.8013\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9693 - val_loss: 0.8829 - val_accuracy: 0.7756\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1183 - accuracy: 0.9388 - val_loss: 0.8887 - val_accuracy: 0.7821\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1028 - accuracy: 0.9617 - val_loss: 0.8850 - val_accuracy: 0.7821\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9688 - val_loss: 0.8894 - val_accuracy: 0.7692\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9620 - val_loss: 0.9090 - val_accuracy: 0.7821\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1117 - accuracy: 0.9592 - val_loss: 0.9115 - val_accuracy: 0.7821\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9573 - val_loss: 0.9160 - val_accuracy: 0.7821\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9367 - val_loss: 0.9270 - val_accuracy: 0.7756\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9614 - val_loss: 0.9231 - val_accuracy: 0.7692\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9649 - val_loss: 0.9301 - val_accuracy: 0.7756\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9656 - val_loss: 0.9267 - val_accuracy: 0.7756\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0787 - accuracy: 0.9857 - val_loss: 0.9293 - val_accuracy: 0.7756\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0854 - accuracy: 0.9785 - val_loss: 0.9241 - val_accuracy: 0.7949\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9772 - val_loss: 0.9391 - val_accuracy: 0.7756\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9750 - val_loss: 0.9485 - val_accuracy: 0.7756\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0835 - accuracy: 0.9615 - val_loss: 0.9514 - val_accuracy: 0.7756\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9802 - val_loss: 0.9539 - val_accuracy: 0.7756\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9660 - val_loss: 0.9779 - val_accuracy: 0.7692\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0715 - accuracy: 0.9881 - val_loss: 0.9589 - val_accuracy: 0.7756\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0848 - accuracy: 0.9770 - val_loss: 0.9799 - val_accuracy: 0.7756\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9898 - val_loss: 0.9703 - val_accuracy: 0.7756\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9868 - val_loss: 0.9898 - val_accuracy: 0.7692\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9827 - val_loss: 1.0067 - val_accuracy: 0.7692\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0624 - accuracy: 0.9857 - val_loss: 0.9969 - val_accuracy: 0.7821\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0823 - accuracy: 0.9855 - val_loss: 0.9953 - val_accuracy: 0.7821\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9880 - val_loss: 0.9944 - val_accuracy: 0.7756\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9922 - val_loss: 1.0074 - val_accuracy: 0.7821\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9843 - val_loss: 1.0113 - val_accuracy: 0.7756\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9786 - val_loss: 1.0147 - val_accuracy: 0.7949\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9881 - val_loss: 1.0143 - val_accuracy: 0.7885\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0672 - accuracy: 0.9814 - val_loss: 1.0272 - val_accuracy: 0.7756\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9862 - val_loss: 1.0336 - val_accuracy: 0.7756\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9877 - val_loss: 1.0515 - val_accuracy: 0.7821\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9809 - val_loss: 1.0517 - val_accuracy: 0.7821\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9689 - val_loss: 1.0515 - val_accuracy: 0.7756\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0469 - accuracy: 0.9907 - val_loss: 1.0595 - val_accuracy: 0.7756\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9861 - val_loss: 1.0603 - val_accuracy: 0.7885\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9833 - val_loss: 1.0642 - val_accuracy: 0.7885\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9902 - val_loss: 1.0791 - val_accuracy: 0.7821\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.9939 - val_loss: 1.0749 - val_accuracy: 0.7821\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.9964 - val_loss: 1.0817 - val_accuracy: 0.7821\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9897 - val_loss: 1.0982 - val_accuracy: 0.7885\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9916 - val_loss: 1.0964 - val_accuracy: 0.7885\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9948 - val_loss: 1.0997 - val_accuracy: 0.7756\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0405 - accuracy: 0.9911 - val_loss: 1.0960 - val_accuracy: 0.8013\n",
      "Epoch 116/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9946 - val_loss: 1.0840 - val_accuracy: 0.8077\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9887 - val_loss: 1.0936 - val_accuracy: 0.8013\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9984 - val_loss: 1.1135 - val_accuracy: 0.8077\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.9998 - val_loss: 1.1239 - val_accuracy: 0.7949\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0459 - accuracy: 0.9952 - val_loss: 1.1134 - val_accuracy: 0.8205\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9932 - val_loss: 1.1315 - val_accuracy: 0.7885\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9924 - val_loss: 1.1468 - val_accuracy: 0.8077\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9969 - val_loss: 1.1496 - val_accuracy: 0.8013\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9954 - val_loss: 1.1468 - val_accuracy: 0.7885\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9936 - val_loss: 1.1619 - val_accuracy: 0.8013\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9917 - val_loss: 1.1539 - val_accuracy: 0.8141\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9946 - val_loss: 1.1609 - val_accuracy: 0.8013\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9932 - val_loss: 1.1767 - val_accuracy: 0.8077\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0335 - accuracy: 0.9922 - val_loss: 1.1753 - val_accuracy: 0.8141\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9923 - val_loss: 1.1678 - val_accuracy: 0.8141\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9960 - val_loss: 1.1927 - val_accuracy: 0.8013\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0310 - accuracy: 0.9976 - val_loss: 1.1927 - val_accuracy: 0.8205\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0288 - accuracy: 0.9987 - val_loss: 1.1805 - val_accuracy: 0.8269\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9990 - val_loss: 1.2023 - val_accuracy: 0.8141\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 0.9976 - val_loss: 1.2041 - val_accuracy: 0.8205\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9929 - val_loss: 1.2068 - val_accuracy: 0.8077\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0265 - accuracy: 0.9960 - val_loss: 1.2171 - val_accuracy: 0.8141\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0316 - accuracy: 0.9954 - val_loss: 1.1969 - val_accuracy: 0.8269\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9953 - val_loss: 1.2199 - val_accuracy: 0.8333\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0338 - accuracy: 0.9998 - val_loss: 1.2175 - val_accuracy: 0.8333\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0262 - accuracy: 0.9968 - val_loss: 1.2179 - val_accuracy: 0.8141\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 0.9998 - val_loss: 1.2249 - val_accuracy: 0.8141\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9995 - val_loss: 1.2224 - val_accuracy: 0.8141\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9956 - val_loss: 1.2299 - val_accuracy: 0.8205\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9980 - val_loss: 1.2093 - val_accuracy: 0.8141\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9916 - val_loss: 1.2315 - val_accuracy: 0.8077\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9955 - val_loss: 1.2274 - val_accuracy: 0.8333\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 0.9998 - val_loss: 1.2472 - val_accuracy: 0.8141\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9954 - val_loss: 1.2497 - val_accuracy: 0.8462\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0227 - accuracy: 0.9978 - val_loss: 1.2542 - val_accuracy: 0.8397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15e0fe19e80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 873us/step - loss: 0.3944 - accuracy: 0.9478\n",
      "accuracy: 94.78%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 8ms/step - loss: 3.8913 - accuracy: 0.7477 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8087 - accuracy: 0.7531 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5741 - accuracy: 0.7683 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8672 - accuracy: 0.7493 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6912 - accuracy: 0.7607 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.4672 - accuracy: 0.7752 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0165 - accuracy: 0.7396 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4125 - accuracy: 0.7788 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8132 - accuracy: 0.7528 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6950 - accuracy: 0.7605 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7248 - accuracy: 0.7585 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6902 - accuracy: 0.7608 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8322 - accuracy: 0.7516 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5771 - accuracy: 0.7681 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6855 - accuracy: 0.7611 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8173 - accuracy: 0.7525 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7062 - accuracy: 0.7597 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8369 - accuracy: 0.7513 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.9537 - accuracy: 0.8085 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6180 - accuracy: 0.7654 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5289 - accuracy: 0.7712 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7695 - accuracy: 0.7556 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.3719 - accuracy: 0.7814 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.2253 - accuracy: 0.7261 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.0356 - accuracy: 0.7384 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3290 - accuracy: 0.7842 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7591 - accuracy: 0.7563 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.9195 - accuracy: 0.7459 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9454 - accuracy: 0.7442 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8496 - accuracy: 0.7504 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4310 - accuracy: 0.7776 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9185 - accuracy: 0.7460 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.2251 - accuracy: 0.7909 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6776 - accuracy: 0.7616 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4093 - accuracy: 0.7790 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.8079 - accuracy: 0.7531 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8449 - accuracy: 0.7507 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7875 - accuracy: 0.7545 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8721 - accuracy: 0.7490 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.4385 - accuracy: 0.7122 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0798 - accuracy: 0.7355 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6193 - accuracy: 0.7654 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6662 - accuracy: 0.7623 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6440 - accuracy: 0.7638 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6898 - accuracy: 0.7608 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8432 - accuracy: 0.7508 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5978 - accuracy: 0.7668 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8475 - accuracy: 0.7506 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4474 - accuracy: 0.7765 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5284 - accuracy: 0.7713 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.2500 - accuracy: 0.7245 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5363 - accuracy: 0.7707 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.1640 - accuracy: 0.7949 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4343 - accuracy: 0.7774 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.2583 - accuracy: 0.7888 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2817 - accuracy: 0.7224 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1067 - accuracy: 0.7338 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.9787 - accuracy: 0.7421 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7553 - accuracy: 0.7565 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6474 - accuracy: 0.7635 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3765 - accuracy: 0.7811 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8560 - accuracy: 0.7500 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5410 - accuracy: 0.7704 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0686 - accuracy: 0.7362 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0711 - accuracy: 0.7361 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3087 - accuracy: 0.7207 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2389 - accuracy: 0.7252 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4694 - accuracy: 0.7751 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9479 - accuracy: 0.7441 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.9499 - accuracy: 0.7439 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6310 - accuracy: 0.7646 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.9563 - accuracy: 0.7435 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8125 - accuracy: 0.7528 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8738 - accuracy: 0.7489 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9897 - accuracy: 0.7413 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5075 - accuracy: 0.7726 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.0504 - accuracy: 0.7374 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.8215 - accuracy: 0.7523 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.0181 - accuracy: 0.7395 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6749 - accuracy: 0.7618 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.6201 - accuracy: 0.7653 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.8259 - accuracy: 0.7520 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.5208 - accuracy: 0.7717 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9386 - accuracy: 0.7447 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1234 - accuracy: 0.7327 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3746 - accuracy: 0.7164 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1242 - accuracy: 0.7326 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7540 - accuracy: 0.7566 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3032 - accuracy: 0.7859 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8214 - accuracy: 0.7523 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8635 - accuracy: 0.7495 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.3524 - accuracy: 0.7178 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7719 - accuracy: 0.7555 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7190 - accuracy: 0.7589 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6551 - accuracy: 0.7630 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7588 - accuracy: 0.7563 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 4.1143 - accuracy: 0.7333 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 3.7019 - accuracy: 0.7600 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9751 - accuracy: 0.7423 - val_loss: 5.0428 - val_accuracy: 0.6731\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5887 - accuracy: 0.7673 - val_loss: 5.0428 - val_accuracy: 0.6731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15e1182d070>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='sigmoid'))\n",
    "model.add(Dense(8,activation='sigmoid'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=100, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 873us/step - loss: 4.1471 - accuracy: 0.7311\n",
      "accuracy: 73.11%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 1s 7ms/step - loss: 2.4010 - accuracy: 0.6287 - val_loss: 3.8963 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.8140 - accuracy: 0.7115 - val_loss: 3.4463 - val_accuracy: 0.5577\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.7235 - accuracy: 0.7146 - val_loss: 3.1833 - val_accuracy: 0.5513\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3908 - accuracy: 0.7515 - val_loss: 3.2992 - val_accuracy: 0.5577\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.6595 - accuracy: 0.7208 - val_loss: 3.2038 - val_accuracy: 0.5385\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.6671 - accuracy: 0.6915 - val_loss: 3.1728 - val_accuracy: 0.5513\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3438 - accuracy: 0.7619 - val_loss: 3.1116 - val_accuracy: 0.5449\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.8188 - accuracy: 0.7412 - val_loss: 3.0016 - val_accuracy: 0.5513\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.4229 - accuracy: 0.7516 - val_loss: 2.8822 - val_accuracy: 0.5513\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.5494 - accuracy: 0.7387 - val_loss: 2.8746 - val_accuracy: 0.5513\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.5072 - accuracy: 0.7342 - val_loss: 2.8721 - val_accuracy: 0.5513\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.4487 - accuracy: 0.7213 - val_loss: 2.8670 - val_accuracy: 0.5577\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2495 - accuracy: 0.7506 - val_loss: 2.7983 - val_accuracy: 0.5577\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3231 - accuracy: 0.7550 - val_loss: 2.7867 - val_accuracy: 0.5577\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3804 - accuracy: 0.7364 - val_loss: 2.7815 - val_accuracy: 0.5513\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.5346 - accuracy: 0.7617 - val_loss: 2.7198 - val_accuracy: 0.5513\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9868 - accuracy: 0.7891 - val_loss: 2.7059 - val_accuracy: 0.5513\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2730 - accuracy: 0.7439 - val_loss: 2.7012 - val_accuracy: 0.5513\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2707 - accuracy: 0.7463 - val_loss: 2.6987 - val_accuracy: 0.5513\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3125 - accuracy: 0.7225 - val_loss: 2.6248 - val_accuracy: 0.5577\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1740 - accuracy: 0.7549 - val_loss: 2.6691 - val_accuracy: 0.5321\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.5340 - accuracy: 0.7411 - val_loss: 2.6586 - val_accuracy: 0.5385\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.5439 - accuracy: 0.7474 - val_loss: 2.5676 - val_accuracy: 0.5577\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3369 - accuracy: 0.7541 - val_loss: 2.5372 - val_accuracy: 0.5641\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2508 - accuracy: 0.7928 - val_loss: 2.5177 - val_accuracy: 0.5449\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2552 - accuracy: 0.7766 - val_loss: 2.5175 - val_accuracy: 0.5449\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1541 - accuracy: 0.7737 - val_loss: 2.5100 - val_accuracy: 0.5577\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1355 - accuracy: 0.7755 - val_loss: 2.4187 - val_accuracy: 0.5769\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2107 - accuracy: 0.7477 - val_loss: 2.3741 - val_accuracy: 0.5897\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3882 - accuracy: 0.7770 - val_loss: 2.3533 - val_accuracy: 0.5897\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.7017 - accuracy: 0.7494 - val_loss: 2.4839 - val_accuracy: 0.5897\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8470 - accuracy: 0.7995 - val_loss: 2.4843 - val_accuracy: 0.5897\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.5968 - accuracy: 0.7336 - val_loss: 2.4863 - val_accuracy: 0.5897\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3421 - accuracy: 0.7877 - val_loss: 2.4817 - val_accuracy: 0.5897\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1747 - accuracy: 0.7838 - val_loss: 2.4754 - val_accuracy: 0.5897\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9884 - accuracy: 0.7982 - val_loss: 2.4994 - val_accuracy: 0.5833\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1789 - accuracy: 0.7499 - val_loss: 2.5590 - val_accuracy: 0.5897\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3612 - accuracy: 0.7605 - val_loss: 2.5592 - val_accuracy: 0.5897\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3228 - accuracy: 0.7477 - val_loss: 2.5625 - val_accuracy: 0.5833\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2606 - accuracy: 0.7883 - val_loss: 2.5090 - val_accuracy: 0.5897\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2175 - accuracy: 0.7876 - val_loss: 2.5054 - val_accuracy: 0.5897\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1714 - accuracy: 0.7621 - val_loss: 2.4957 - val_accuracy: 0.5897\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1624 - accuracy: 0.7805 - val_loss: 2.4906 - val_accuracy: 0.5897\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.3458 - accuracy: 0.7761 - val_loss: 2.4894 - val_accuracy: 0.5897\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8955 - accuracy: 0.7711 - val_loss: 2.4919 - val_accuracy: 0.5897\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1113 - accuracy: 0.7847 - val_loss: 2.4329 - val_accuracy: 0.5897\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.4770 - accuracy: 0.7824 - val_loss: 2.5073 - val_accuracy: 0.5897\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0549 - accuracy: 0.7911 - val_loss: 2.5056 - val_accuracy: 0.5897\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8855 - accuracy: 0.8073 - val_loss: 2.4921 - val_accuracy: 0.5962\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2403 - accuracy: 0.7840 - val_loss: 2.4842 - val_accuracy: 0.5897\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9754 - accuracy: 0.8039 - val_loss: 2.4824 - val_accuracy: 0.5897\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1337 - accuracy: 0.7777 - val_loss: 2.4791 - val_accuracy: 0.5897\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1835 - accuracy: 0.7660 - val_loss: 2.4391 - val_accuracy: 0.5897\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0221 - accuracy: 0.8087 - val_loss: 2.4817 - val_accuracy: 0.5897\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2980 - accuracy: 0.7859 - val_loss: 2.4857 - val_accuracy: 0.5897\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0838 - accuracy: 0.7858 - val_loss: 2.4806 - val_accuracy: 0.5962\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.0262 - accuracy: 0.8015 - val_loss: 2.4796 - val_accuracy: 0.5962\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1926 - accuracy: 0.7980 - val_loss: 2.4846 - val_accuracy: 0.5962\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2599 - accuracy: 0.7728 - val_loss: 2.4821 - val_accuracy: 0.6026\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9563 - accuracy: 0.7973 - val_loss: 2.5431 - val_accuracy: 0.6026\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.8116 - accuracy: 0.8190 - val_loss: 2.4908 - val_accuracy: 0.6026\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9142 - accuracy: 0.8222 - val_loss: 2.5422 - val_accuracy: 0.6026\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3743 - accuracy: 0.7906 - val_loss: 2.5398 - val_accuracy: 0.6026\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.4450 - accuracy: 0.7455 - val_loss: 2.5407 - val_accuracy: 0.6026\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.4109 - accuracy: 0.7905 - val_loss: 2.5385 - val_accuracy: 0.6026\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.4272 - accuracy: 0.7597 - val_loss: 2.5359 - val_accuracy: 0.6154\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1643 - accuracy: 0.8063 - val_loss: 2.4784 - val_accuracy: 0.6218\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.8115 - accuracy: 0.8100 - val_loss: 2.5341 - val_accuracy: 0.6218\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1293 - accuracy: 0.7773 - val_loss: 2.4591 - val_accuracy: 0.5962\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9456 - accuracy: 0.7916 - val_loss: 2.4611 - val_accuracy: 0.6090\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0626 - accuracy: 0.7655 - val_loss: 2.4642 - val_accuracy: 0.6154\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0127 - accuracy: 0.8125 - val_loss: 2.4659 - val_accuracy: 0.6218\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2717 - accuracy: 0.7589 - val_loss: 2.4931 - val_accuracy: 0.6090\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1502 - accuracy: 0.7799 - val_loss: 2.5560 - val_accuracy: 0.6154\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0663 - accuracy: 0.7911 - val_loss: 2.5576 - val_accuracy: 0.6154\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9107 - accuracy: 0.8254 - val_loss: 2.6129 - val_accuracy: 0.6282\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2054 - accuracy: 0.7957 - val_loss: 2.6128 - val_accuracy: 0.6282\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2824 - accuracy: 0.7683 - val_loss: 2.6223 - val_accuracy: 0.6218\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3548 - accuracy: 0.7839 - val_loss: 2.6192 - val_accuracy: 0.6218\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9998 - accuracy: 0.7937 - val_loss: 2.6147 - val_accuracy: 0.6218\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.2162 - accuracy: 0.7799 - val_loss: 2.6215 - val_accuracy: 0.6154\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9791 - accuracy: 0.8090 - val_loss: 2.6284 - val_accuracy: 0.6154\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1970 - accuracy: 0.8007 - val_loss: 2.6296 - val_accuracy: 0.6154\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9683 - accuracy: 0.8213 - val_loss: 2.6925 - val_accuracy: 0.5962\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0546 - accuracy: 0.7890 - val_loss: 2.6871 - val_accuracy: 0.5962\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1696 - accuracy: 0.8148 - val_loss: 2.6883 - val_accuracy: 0.5962\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2715 - accuracy: 0.7994 - val_loss: 2.6881 - val_accuracy: 0.6090\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0109 - accuracy: 0.8003 - val_loss: 2.6866 - val_accuracy: 0.6090\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1182 - accuracy: 0.8102 - val_loss: 2.6846 - val_accuracy: 0.6090\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9337 - accuracy: 0.8188 - val_loss: 2.6854 - val_accuracy: 0.6154\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9253 - accuracy: 0.8495 - val_loss: 2.6835 - val_accuracy: 0.6090\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.9552 - accuracy: 0.8195 - val_loss: 2.6814 - val_accuracy: 0.6154\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.2018 - accuracy: 0.8081 - val_loss: 2.6851 - val_accuracy: 0.6218\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3157 - accuracy: 0.7675 - val_loss: 2.6830 - val_accuracy: 0.6218\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.7756 - accuracy: 0.8489 - val_loss: 2.6826 - val_accuracy: 0.6218\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.0249 - accuracy: 0.7916 - val_loss: 2.6811 - val_accuracy: 0.6282\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.1947 - accuracy: 0.8101 - val_loss: 2.6820 - val_accuracy: 0.6218\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.3031 - accuracy: 0.7888 - val_loss: 2.6859 - val_accuracy: 0.6218\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 1.1161 - accuracy: 0.8270 - val_loss: 2.6811 - val_accuracy: 0.6218\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.9083 - accuracy: 0.8406 - val_loss: 2.6802 - val_accuracy: 0.6218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15e11bdf490>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=100, batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 811us/step - loss: 1.5948 - accuracy: 0.7563\n",
      "accuracy: 75.63%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 1s 5ms/step - loss: 2.3320 - accuracy: 0.4904 - val_loss: 2.3256 - val_accuracy: 0.4936\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.4475 - accuracy: 0.6431 - val_loss: 2.0459 - val_accuracy: 0.5192\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0055 - accuracy: 0.6718 - val_loss: 1.9609 - val_accuracy: 0.5385\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0102 - accuracy: 0.6809 - val_loss: 1.7107 - val_accuracy: 0.5513\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.1166 - accuracy: 0.6782 - val_loss: 1.6899 - val_accuracy: 0.5577\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8929 - accuracy: 0.7003 - val_loss: 1.6807 - val_accuracy: 0.5833\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.9565 - accuracy: 0.6854 - val_loss: 1.5996 - val_accuracy: 0.5769\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0182 - accuracy: 0.7496 - val_loss: 1.4107 - val_accuracy: 0.5962\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 1.0165 - accuracy: 0.7174 - val_loss: 1.3763 - val_accuracy: 0.5962\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8551 - accuracy: 0.7424 - val_loss: 1.2917 - val_accuracy: 0.5897\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8396 - accuracy: 0.7389 - val_loss: 1.2892 - val_accuracy: 0.5962\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8978 - accuracy: 0.7329 - val_loss: 1.2807 - val_accuracy: 0.5962\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6337 - accuracy: 0.7828 - val_loss: 1.2785 - val_accuracy: 0.5962\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8600 - accuracy: 0.7283 - val_loss: 1.2045 - val_accuracy: 0.5769\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7802 - val_loss: 1.1992 - val_accuracy: 0.5833\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7405 - val_loss: 1.1978 - val_accuracy: 0.5897\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.8967 - accuracy: 0.7754 - val_loss: 1.0641 - val_accuracy: 0.6282\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6373 - accuracy: 0.7821 - val_loss: 0.9434 - val_accuracy: 0.6282\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7893 - val_loss: 0.9230 - val_accuracy: 0.6410\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7876 - val_loss: 0.9192 - val_accuracy: 0.6410\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8063 - val_loss: 0.9164 - val_accuracy: 0.6410\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7897 - val_loss: 0.9093 - val_accuracy: 0.6410\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.8303 - val_loss: 0.9171 - val_accuracy: 0.6474\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7846 - val_loss: 0.9171 - val_accuracy: 0.6603\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8000 - val_loss: 0.9090 - val_accuracy: 0.6538\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8125 - val_loss: 0.9221 - val_accuracy: 0.6603\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6356 - accuracy: 0.7592 - val_loss: 0.9213 - val_accuracy: 0.6603\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.8337 - val_loss: 1.5948 - val_accuracy: 0.6667\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5712 - accuracy: 0.7702 - val_loss: 1.3030 - val_accuracy: 0.6667\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4443 - accuracy: 0.8037 - val_loss: 1.2807 - val_accuracy: 0.6474\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7720 - val_loss: 1.1992 - val_accuracy: 0.6474\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8205 - val_loss: 1.1934 - val_accuracy: 0.6538\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3940 - accuracy: 0.7920 - val_loss: 1.1956 - val_accuracy: 0.6410\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3881 - accuracy: 0.8525 - val_loss: 1.2094 - val_accuracy: 0.6474\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8122 - val_loss: 1.2107 - val_accuracy: 0.6474\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.8100 - val_loss: 1.1358 - val_accuracy: 0.6474\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8257 - val_loss: 1.2084 - val_accuracy: 0.6474\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6113 - accuracy: 0.7867 - val_loss: 1.2094 - val_accuracy: 0.6538\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.8273 - val_loss: 1.2245 - val_accuracy: 0.6603\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4143 - accuracy: 0.8378 - val_loss: 1.2238 - val_accuracy: 0.6538\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8333 - val_loss: 1.1572 - val_accuracy: 0.6603\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8013 - val_loss: 1.1488 - val_accuracy: 0.6603\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8228 - val_loss: 1.2236 - val_accuracy: 0.6667\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8398 - val_loss: 1.1570 - val_accuracy: 0.6667\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4200 - accuracy: 0.8255 - val_loss: 1.2010 - val_accuracy: 0.6667\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.8239 - val_loss: 1.1907 - val_accuracy: 0.6667\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8600 - val_loss: 1.1948 - val_accuracy: 0.6667\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8400 - val_loss: 1.1894 - val_accuracy: 0.6603\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8499 - val_loss: 1.1833 - val_accuracy: 0.6795\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8395 - val_loss: 1.1780 - val_accuracy: 0.6795\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4318 - accuracy: 0.8232 - val_loss: 1.1689 - val_accuracy: 0.6859\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8726 - val_loss: 1.1689 - val_accuracy: 0.6731\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4194 - accuracy: 0.8570 - val_loss: 1.1610 - val_accuracy: 0.6923\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3839 - accuracy: 0.8250 - val_loss: 1.1510 - val_accuracy: 0.6987\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8667 - val_loss: 1.1471 - val_accuracy: 0.6987\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3828 - accuracy: 0.8277 - val_loss: 1.1441 - val_accuracy: 0.6987\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8492 - val_loss: 1.1429 - val_accuracy: 0.6987\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.8399 - val_loss: 1.1435 - val_accuracy: 0.6987\n",
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8326 - val_loss: 1.1388 - val_accuracy: 0.6923\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.8530 - val_loss: 1.1443 - val_accuracy: 0.7051\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4403 - accuracy: 0.8394 - val_loss: 1.1329 - val_accuracy: 0.7115\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8505 - val_loss: 1.1393 - val_accuracy: 0.7051\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2948 - accuracy: 0.8825 - val_loss: 1.1318 - val_accuracy: 0.7051\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3699 - accuracy: 0.8374 - val_loss: 1.1292 - val_accuracy: 0.7115\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8315 - val_loss: 1.2050 - val_accuracy: 0.7115\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8549 - val_loss: 1.2015 - val_accuracy: 0.7115\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8494 - val_loss: 1.1990 - val_accuracy: 0.7115\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3607 - accuracy: 0.8651 - val_loss: 1.1947 - val_accuracy: 0.7179\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8604 - val_loss: 1.1966 - val_accuracy: 0.7179\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3396 - accuracy: 0.8674 - val_loss: 1.1895 - val_accuracy: 0.7179\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8716 - val_loss: 1.1846 - val_accuracy: 0.7179\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3879 - accuracy: 0.8720 - val_loss: 1.1889 - val_accuracy: 0.7115\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4223 - accuracy: 0.8682 - val_loss: 1.2515 - val_accuracy: 0.7179\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3410 - accuracy: 0.8746 - val_loss: 1.2519 - val_accuracy: 0.7179\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3221 - accuracy: 0.8826 - val_loss: 1.2390 - val_accuracy: 0.7115\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8834 - val_loss: 1.2443 - val_accuracy: 0.7179\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3597 - accuracy: 0.8960 - val_loss: 1.2507 - val_accuracy: 0.6987\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8951 - val_loss: 1.2449 - val_accuracy: 0.7179\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3374 - accuracy: 0.9168 - val_loss: 1.2377 - val_accuracy: 0.7051\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2549 - accuracy: 0.9103 - val_loss: 1.2365 - val_accuracy: 0.7115\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2311 - accuracy: 0.9009 - val_loss: 1.2493 - val_accuracy: 0.7179\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8540 - val_loss: 1.3498 - val_accuracy: 0.7179\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3467 - accuracy: 0.8618 - val_loss: 1.3302 - val_accuracy: 0.7179\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2590 - accuracy: 0.9033 - val_loss: 1.3416 - val_accuracy: 0.6987\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3051 - accuracy: 0.9150 - val_loss: 1.3268 - val_accuracy: 0.7115\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3648 - accuracy: 0.8831 - val_loss: 1.2179 - val_accuracy: 0.7179\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3878 - accuracy: 0.9138 - val_loss: 1.2508 - val_accuracy: 0.7115\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2520 - accuracy: 0.9249 - val_loss: 1.3194 - val_accuracy: 0.7115\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2183 - accuracy: 0.9167 - val_loss: 1.3959 - val_accuracy: 0.7179\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8972 - val_loss: 1.3706 - val_accuracy: 0.7436\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9306 - val_loss: 1.3769 - val_accuracy: 0.7436\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2515 - accuracy: 0.9024 - val_loss: 1.4528 - val_accuracy: 0.7372\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9114 - val_loss: 1.4375 - val_accuracy: 0.7436\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.8972 - val_loss: 1.3621 - val_accuracy: 0.7308\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.9212 - val_loss: 1.3517 - val_accuracy: 0.7500\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.9352 - val_loss: 1.4318 - val_accuracy: 0.7372\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9417 - val_loss: 1.4150 - val_accuracy: 0.7564\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.9253 - val_loss: 1.4207 - val_accuracy: 0.7308\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.9307 - val_loss: 1.4127 - val_accuracy: 0.7500\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.9167 - val_loss: 1.4185 - val_accuracy: 0.7372\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2120 - accuracy: 0.9250 - val_loss: 1.3669 - val_accuracy: 0.7436\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9550 - val_loss: 1.3549 - val_accuracy: 0.7500\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.9454 - val_loss: 1.3719 - val_accuracy: 0.7372\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2200 - accuracy: 0.9389 - val_loss: 1.4239 - val_accuracy: 0.7436\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3299 - accuracy: 0.9240 - val_loss: 1.4142 - val_accuracy: 0.7500\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9443 - val_loss: 1.4341 - val_accuracy: 0.7436\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1932 - accuracy: 0.9256 - val_loss: 1.4173 - val_accuracy: 0.7500\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.9391 - val_loss: 1.3483 - val_accuracy: 0.7500\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.9603 - val_loss: 1.6141 - val_accuracy: 0.7308\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1635 - accuracy: 0.9303 - val_loss: 1.4195 - val_accuracy: 0.7564\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1912 - accuracy: 0.9419 - val_loss: 1.5065 - val_accuracy: 0.7500\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1419 - accuracy: 0.9371 - val_loss: 1.4628 - val_accuracy: 0.7372\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1473 - accuracy: 0.9478 - val_loss: 1.4893 - val_accuracy: 0.7179\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1532 - accuracy: 0.9239 - val_loss: 1.5804 - val_accuracy: 0.7115\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9351 - val_loss: 1.3866 - val_accuracy: 0.7244\n",
      "Epoch 116/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1115 - accuracy: 0.9504 - val_loss: 1.2883 - val_accuracy: 0.7564\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9451 - val_loss: 1.3561 - val_accuracy: 0.7436\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9392 - val_loss: 1.3487 - val_accuracy: 0.7628\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1005 - accuracy: 0.9638 - val_loss: 1.4238 - val_accuracy: 0.7564\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1144 - accuracy: 0.9323 - val_loss: 1.4143 - val_accuracy: 0.7564\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1083 - accuracy: 0.9454 - val_loss: 1.3454 - val_accuracy: 0.7628\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9457 - val_loss: 1.4281 - val_accuracy: 0.7500\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9679 - val_loss: 1.6546 - val_accuracy: 0.7628\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9500 - val_loss: 1.6093 - val_accuracy: 0.7564\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9741 - val_loss: 1.5926 - val_accuracy: 0.7564\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 0.9468 - val_loss: 1.5917 - val_accuracy: 0.7564\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9609 - val_loss: 1.6212 - val_accuracy: 0.7564\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9611 - val_loss: 1.5844 - val_accuracy: 0.7692\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9284 - val_loss: 1.6105 - val_accuracy: 0.7564\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0890 - accuracy: 0.9609 - val_loss: 1.5963 - val_accuracy: 0.7564\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9526 - val_loss: 1.6971 - val_accuracy: 0.7628\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9620 - val_loss: 1.6791 - val_accuracy: 0.7564\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0800 - accuracy: 0.9565 - val_loss: 1.6935 - val_accuracy: 0.7628\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9639 - val_loss: 1.7568 - val_accuracy: 0.7564\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9482 - val_loss: 1.6894 - val_accuracy: 0.7564\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9618 - val_loss: 1.6807 - val_accuracy: 0.7628\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9661 - val_loss: 1.8453 - val_accuracy: 0.7564\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9630 - val_loss: 1.7776 - val_accuracy: 0.7564\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0945 - accuracy: 0.9519 - val_loss: 1.8517 - val_accuracy: 0.7564\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9715 - val_loss: 1.8086 - val_accuracy: 0.7564\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9556 - val_loss: 1.9349 - val_accuracy: 0.7564\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0768 - accuracy: 0.9531 - val_loss: 1.8609 - val_accuracy: 0.7564\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9577 - val_loss: 1.7921 - val_accuracy: 0.7564\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9739 - val_loss: 1.8096 - val_accuracy: 0.7564\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0465 - accuracy: 0.9781 - val_loss: 1.7239 - val_accuracy: 0.7564\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0840 - accuracy: 0.9425 - val_loss: 1.8741 - val_accuracy: 0.7564\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9672 - val_loss: 1.7810 - val_accuracy: 0.7564\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0837 - accuracy: 0.9411 - val_loss: 1.7697 - val_accuracy: 0.7628\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0687 - accuracy: 0.9654 - val_loss: 1.6245 - val_accuracy: 0.7692\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0490 - accuracy: 0.9701 - val_loss: 1.7823 - val_accuracy: 0.7628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15e13065610>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 748us/step - loss: 0.5766 - accuracy: 0.9130\n",
      "accuracy: 91.30%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out of all the 4 Iterations we are getting best accuracy with Iteration 1 - 94.78%. So we can go ahead with those combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
